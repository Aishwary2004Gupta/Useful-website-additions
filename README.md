Unit 1: Deep Learning Foundations and Neural Network Implementation
1. Which of the following is a fundamental component for introducing non-linearity into a neural network's output? a) Loss function b) Optimizer c) Activation function d) Batch size Correct Answer: c)
2. What is the primary purpose of regularization methods in deep learning? a) To speed up the training process b) To increase the model's capacity c) To prevent overfitting d) To adjust the learning rate dynamically Correct Answer: c)
3. When evaluating a neural network, which strategy is crucial for assessing its generalization performance on unseen data? a) Training on the entire dataset b) Using a very large learning rate c) Validation strategies d) Reducing the number of layers Correct Answer: c)
4. The process of defining the structure of a neural network, including the number of layers and neurons per layer, is known as: a) Model compilation b) Data preprocessing c) Neural network architecture design d) Hyperparameter tuning Correct Answer: c)
5. Which framework is explicitly mentioned for its role in the installation and configuration for neural network implementation in Unit 1? a) TensorFlow b) PyTorch c) Scikit-learn d) Keras Correct Answer: d)
6. During the training process of a neural network, what does a "loss function" primarily measure? a) The speed of convergence b) The discrepancy between predicted and actual outputs c) The memory usage of the model d) The number of epochs completed Correct Answer: b)
7. Optimizers like Stochastic Gradient Descent (SGD) or Adam are used in neural networks for: a) Defining the network's architecture b) Adjusting the network's weights during training c) Calculating the final performance metrics d) Preventing underfitting Correct Answer: b)
8. Which of these is NOT a typical performance metric used for evaluating neural networks? a) Accuracy b) Precision c) Recall d) Installation time Correct Answer: d)
9. What is the objective of "model compilation" in the Keras framework? a) To preprocess the input data b) To configure the learning process with an optimizer, loss function, and metrics c) To visualize the network architecture d) To save the trained model to disk Correct Answer: b)
10. A practical implementation of deep learning projects in Unit 1 involves hands-on experience with: a) Assembly language programming b) Building and training neural networks c) Quantum computing algorithms d) Manual feature engineering only Correct Answer: b)
11. Deep learning concepts and applications are introduced to provide: a) Only theoretical understanding b) A historical overview of computing c) A foundational understanding of the field d) Solutions for traditional machine learning problems exclusively Correct Answer: c)
12. Which of the following best describes the role of "validation strategies" in deep learning? a) Training the model on all available data b) Assessing model performance on data not used for training c) Selecting the initial weights of the network d) Defining the activation functions Correct Answer: b)
13. The process of "building and training neural networks" refers to: a) Creating the model structure and adjusting its parameters using data b) Only creating the model structure c) Only adjusting the parameters manually d) Deploying the model into production Correct Answer: a)
14. What is the significance of "practical implementation of deep learning projects" in Unit 1? a) It is an optional step that can be skipped b) It primarily focuses on theoretical discussions c) It allows students to apply learned concepts to real-world scenarios d) It only involves reviewing existing code Correct Answer: c)
15. Overfitting prevention is a critical aspect of neural network training because it: a) Ensures the model always achieves 100% accuracy b) Helps the model generalize better to new, unseen data c) Speeds up the model's inference time d) Reduces the computational cost of training Correct Answer: b)
Unit 2: Advanced Deep Learning with Keras and TensorFlow
16. Which advanced neural network architecture is primarily used for image processing tasks? a) Recurrent Neural Networks (RNNs) b) Long Short-Term Memory (LSTM) networks c) Convolutional Neural Networks (CNNs) d) Multilayer Perceptrons (MLPs) Correct Answer: c)
17. Recurrent Neural Networks (RNNs) are specifically designed for: a) Image classification and object detection b) Sequence modeling tasks c) Tabular data analysis d) Unsupervised clustering Correct Answer: b)
18. Long Short-Term Memory (LSTM) networks are a type of RNN primarily addressing the issue of: a) Overfitting in deep networks b) Vanishing/exploding gradients in long sequences c) Slow training times d) Lack of interpretability Correct Answer: b)
19. What is the main benefit of using "batch normalization" in advanced neural networks? a) Reduces the number of parameters b) Stabilizes learning and reduces training time c) Increases the network's interpretability d) Makes the network shallower Correct Answer: b)
20. "Dropout" is a regularization technique that works by: a) Adding noise to the input data b) Randomly setting a fraction of neurons to zero during training c) Reducing the learning rate after each epoch d) Increasing the weight decay Correct Answer: b)
21. The integration of "TensorFlow framework with Keras" allows for: a) Limiting Keras functionalities b) Leveraging TensorFlow's backend capabilities and ecosystem within Keras c) Eliminating the need for custom layers d) Only deploying models, not training them Correct Answer: b)
22. "Transfer learning" involves: a) Training a model from scratch on a large dataset b) Using a pre-trained model as a starting point for a new task c) Transferring data between different models d) Transferring model weights between different Keras versions Correct Answer: b)
23. When would "custom layer creation" be necessary in Keras? a) For all standard deep learning tasks b) When existing Keras layers do not meet specific architectural needs c) Only for very shallow networks d) To significantly reduce training time Correct Answer: b)
24. "Production deployment considerations" in advanced deep learning focus on: a) Only the theoretical aspects of model design b) Making models efficient, scalable, and reliable for real-world use c) Initializing random weights for new models d) Exclusive use of CPU-based inference Correct Answer: b)
25. "Model optimization and performance tuning" primarily aims to: a) Reduce the dataset size b) Improve model accuracy, speed, and efficiency c) Change the programming language used d) Convert the model to a different file format Correct Answer: b)
26. Which statement accurately describes "advanced neural network architectures"? a) They are always simpler than basic feedforward networks. b) They include specialized designs like CNNs and RNNs for complex tasks. c) They only use linear activation functions. d) They do not require an optimizer for training. Correct Answer: b)
27. What is a common application of CNNs mentioned in the sources? a) Text summarization b) Stock market prediction c) Image processing d) Speech synthesis Correct Answer: c)
28. The use of "pre-trained models" in advanced deep learning is a core concept of: a) Custom layer creation b) Transfer learning c) Batch normalization d) Dropout techniques Correct Answer: b)
29. Techniques like batch normalization and dropout are primarily used for: a) Increasing model complexity indefinitely b) Improving model generalization and stability c) Reducing the amount of training data needed d) Eliminating the need for activation functions Correct Answer: b)
30. In the context of Unit 2, "model customization" often involves: a) Only changing the optimizer b) Creating custom layers or combining existing layers in unique ways c) Reducing the dataset size for training d) Setting a fixed learning rate for all models Correct Answer: b)
Unit 3: Generative AI Architecture and LLM Fundamentals
31. What is a core characteristic of the Transformer architecture? a) Recurrent connections for sequence processing b) Reliance on convolutional filters for feature extraction c) Extensive use of attention mechanisms d) Small memory footprint due to limited parameters Correct Answer: c)
32. Which of the following is a crucial step in "data preparation techniques for LLM training"? a) Model compression b) Tokenization and vocabulary management c) Reinforcement learning from human feedback d) Distributed training Correct Answer: b)
33. BERT and GPT are examples of what in Natural Language Processing? a) Traditional statistical models b) Rule-based expert systems c) Foundational models d) Simple feedforward networks Correct Answer: c)
34. "Pre-training and fine-tuning methodologies" are essential for LLMs because: a) They allow models to learn from very small datasets initially. b) Pre-training learns general language understanding, while fine-tuning adapts to specific tasks. c) They are only used for image generation. d) They bypass the need for any data preparation. Correct Answer: b)
35. "Ethical considerations in LLM development" address concerns such as: a) Computational cost only b) Bias, fairness, and potential misuse of generative capabilities c) Speed of token generation d) Choice of programming language Correct Answer: b)
36. What is the primary role of "attention mechanisms" in the Transformer architecture? a) To add non-linearity to the network b) To reduce the dimensionality of the input c) To weigh the importance of different parts of the input sequence d) To perform convolution operations Correct Answer: c)
37. "Tokenization" for LLM training involves: a) Encrypting the input text b) Breaking down text into smaller units (tokens) c) Translating text into different languages d) Compressing text files Correct Answer: b)
38. "Foundational models for Natural Language Processing" are characterized by their: a) Small size and limited capabilities b) Ability to perform a wide range of NLP tasks after pre-training c) Dependence on rule-based grammar systems d) Exclusive use of recurrent neural networks Correct Answer: b)
39. "Language understanding and generation capabilities" of LLMs refer to their ability to: a) Only translate text between languages b) Interpret human language and produce coherent, contextually relevant text c) Generate random sequences of words d) Perform numerical calculations exclusively Correct Answer: b)
40. Comparing BERT and GPT typically highlights differences in their: a) Programming language used b) Architectural focus (e.g., encoder-decoder vs. decoder-only for primary tasks) c) Preferred hardware for deployment d) Type of activation functions Correct Answer: b)
41. "Performance evaluation metrics for language models" could include: a) GPU temperature b) Perplexity, BLEU score, ROUGE score c) Number of layers d) Training data size in bytes Correct Answer: b)
42. What are "Large Language Model architecture and design principles" concerned with? a) The physical dimensions of server racks b) The fundamental structure and theoretical underpinnings of LLMs c) Ethical considerations only d) Marketing strategies for AI products Correct Answer: b)
43. "Vocabulary management" in LLM training is critical for: a) Choosing the best marketing terms b) Handling the set of unique tokens the model can process c) Managing physical storage for datasets d) Controlling the learning rate Correct Answer: b)
44. The concept of "Generative AI Architecture" focuses on models capable of: a) Only classifying data b) Creating new, original content (e.g., text, images) c) Performing mathematical calculations d) Retrieving information without modification Correct Answer: b)
45. Why are "ethical considerations" important in LLM development? a) To speed up model training b) To comply with hardware specifications c) To ensure responsible and safe deployment, mitigating potential harms d) To reduce the number of parameters in the model Correct Answer: c)
Unit 4: Language Modeling and Transformer Implementation
46. What is the role of "positional encoding" in the Transformer architecture? a) To replace the need for attention mechanisms b) To provide information about the relative or absolute position of tokens in a sequence c) To reduce the computational cost of self-attention d) To embed words into a vector space without order information Correct Answer: b)
47. The "self-attention mechanism" in Transformers allows the model to: a) Only focus on the most recent token b) Weigh the importance of all other tokens in the input sequence relative to a given token c) Process tokens sequentially in a fixed order d) Perform convolutional operations on the input Correct Answer: b)
48. "Multi-head attention mechanisms" enhance the Transformer's ability to: a) Reduce the number of layers b) Attend to different aspects of the input simultaneously and learn richer representations c) Process only short sequences efficiently d) Eliminate the need for positional encoding Correct Answer: b)
49. "Decoder-only models" in Transformers are primarily used for: a) Classification tasks b) Generative language modeling c) Machine translation (input to output sequence of different languages) d) Image recognition Correct Answer: b)
50. "Encoder-decoder models" are commonly employed in tasks like: a) Text summarization (abstractive) b) Image captioning c) Machine translation d) All of the above Correct Answer: d)
51. Which token generation strategy introduces randomness to the output, where a higher value leads to more diverse (and potentially less coherent) text? a) Beam search b) Top-k sampling c) Nucleus sampling d) Temperature sampling Correct Answer: d)
52. "Beam search" is a decoding strategy that aims to: a) Generate the most diverse output possible b) Find the sequence of tokens with the highest probability c) Only consider one token at a time d) Randomly select the next token Correct Answer: b)
53. "Fine-tuning transformers for specific tasks" involves: a) Training the entire transformer model from scratch b) Adapting a pre-trained transformer model to a downstream task with a smaller, task-specific dataset c) Changing the base architecture of the transformer d) Removing the attention mechanisms Correct Answer: b)
54. "Custom model training and optimization" in the context of Transformers allows for: a) Only using pre-defined models b) Developing and refining transformer models for unique requirements c) Eliminating the need for GPUs d) Disabling all attention mechanisms Correct Answer: b)
55. "Generative AI language modeling techniques" focus on: a) Analyzing existing text for patterns b) Generating new, coherent, and contextually relevant text c) Classifying text into predefined categories d) Extracting specific information from text Correct Answer: b)
56. What does "sequence processing" entail in Transformer models? a) Only processing single words b) Handling an ordered series of items (e.g., words in a sentence) c) Processing images in a grid format d) Randomly arranging input data Correct Answer: b)
57. "Top-k sampling" for token generation involves: a) Always picking the token with the highest probability b) Sampling from the k most likely next tokens c) Sampling from all possible tokens equally d) Completely ignoring token probabilities Correct Answer: b)
58. "Nucleus sampling" (top-p sampling) improves upon top-k sampling by: a) Always choosing the top-k tokens b) Sampling from the smallest set of most probable tokens whose cumulative probability exceeds a threshold 'p' c) Only considering tokens with 0 probability d) Eliminating all low-probability tokens Correct Answer: b)
59. What is a key advantage of the Transformer architecture's "parallel processing" capability? a) It makes the model simpler. b) It allows for faster training times compared to sequential RNNs. c) It requires less memory. d) It removes the need for optimizers. Correct Answer: b)
60. "Transformer architecture deep dive" implies understanding: a) Only the high-level concept of attention b) The intricate details of its components like self-attention, multi-head attention, and feed-forward networks c) The history of deep learning d) Only its application in image processing Correct Answer: b)
Unit 5: Advanced Fine-Tuning and LLM Engineering
61. Which parameter-efficient fine-tuning method involves using low-rank matrices to adapt pre-trained models? a) Quantization strategies b) LoRA (Low-Rank Adaptation) techniques c) Instruction tuning d) Distributed training Correct Answer: b)
62. "QLoRA" is an advanced fine-tuning technique that combines LoRA with: a) Domain adaptation b) Quantization strategies c) Reinforcement Learning from Human Feedback (RLHF) d) Multi-modal AI applications Correct Answer: b)
63. What is the primary goal of "Reinforcement Learning from Human Feedback (RLHF)" in LLM engineering? a) To compress models for deployment b) To adapt models to new domains c) To align model behavior with human preferences and instructions d) To implement distributed training strategies Correct Answer: c)
64. "Instruction tuning" is a technique used to: a) Reduce the size of the model b) Improve an LLM's ability to follow explicit instructions and generalize to new tasks c) Only optimize for speed d) Change the model's foundational architecture Correct Answer: b)
65. "Domain adaptation" in advanced fine-tuning aims to: a) Make the model perform worse in its original domain b) Tailor a pre-trained model to perform well on data from a specific target domain c) Eliminate the need for any training data d) Increase the overall model size significantly Correct Answer: b)
66. "Model compression and optimization" techniques are crucial for: a) Making models larger and more complex b) Reducing model size and improving inference speed for deployment c) Increasing the number of training parameters d) Extending the training duration Correct Answer: b)
67. "Distributed training strategies" are often employed when: a) Training a very small model on a single GPU b) Training very large models that exceed the capacity of a single device c) The model is already deployed in production d) Only for traditional machine learning algorithms Correct Answer: b)
68. "Production-ready LLM deployment" involves considerations such as: a) Only the initial model design b) Scalability, latency, cost-effectiveness, and continuous monitoring c) Writing academic papers about the model d) Eliminating all ethical considerations Correct Answer: b)
69. "Parameter-efficient fine-tuning methods" like LoRA are valuable because they: a) Require retraining the entire model b) Reduce the number of parameters that need to be trained, saving computational resources and time c) Are only applicable to very small datasets d) Increase the complexity of model deployment Correct Answer: b)
70. "Advanced fine-tuning for specialized applications" implies: a) Using general-purpose fine-tuning methods for all tasks b) Customizing fine-tuning approaches to achieve optimal performance for niche or complex use cases c) Avoiding fine-tuning altogether d) Only focusing on image recognition tasks Correct Answer: b)
71. Which of the following is a key aspect of "alignment techniques" in LLM engineering? a) Randomly initializing all model weights b) Ensuring the LLM's outputs are helpful, harmless, and honest c) Reducing the vocabulary size to a minimum d) Increasing the model's training time exponentially Correct Answer: b)
72. Quantization strategies in LLM engineering help with: a) Increasing the model's precision b) Reducing the memory footprint and accelerating inference by using lower precision data types c) Adding more layers to the model d) Enhancing the diversity of generated text Correct Answer: b)
73. The concept of "LLM Engineering" encompasses: a) Only the theoretical understanding of LLMs b) The practical aspects of building, optimizing, and deploying LLMs effectively c) Solely focusing on data collection d) Exclusively designing new foundational architectures Correct Answer: b)
74. When implementing "distributed training strategies," what is a common challenge? a) Lack of available training data b) Managing communication and synchronization between multiple devices/nodes c) Finding appropriate activation functions d) Choosing the right programming language Correct Answer: b)
75. What is the primary benefit of "model compression" for LLMs? a) It makes the model more accurate. b) It enables deployment on resource-constrained devices and reduces inference costs. c) It increases the model's training time. d) It makes the model less secure. Correct Answer: b)
Unit 6: AI Agents and RAG Applications with LangChain
76. What does RAG stand for in the context of AI agent systems? a) Random Access Generation b) Reinforcement Agent Grid c) Retrieval-Augmented Generation d) Resource Allocation Graph Correct Answer: c)
77. The LangChain framework is designed for what primary purpose? a) Optimizing neural network performance b) Installing deep learning frameworks c) Building generative AI-powered applications, especially with RAG architecture d) Training foundational NLP models from scratch Correct Answer: c)
78. In RAG architecture, "vector databases and semantic search" are used to: a) Store large language models b) Efficiently store and retrieve relevant information based on semantic similarity c) Manage agent workflows d) Generate new text without external data Correct Answer: b)
79. What is the role of "embedding models" in a RAG system? a) To perform random data generation b) To convert text (or other data) into numerical vector representations for similarity search c) To manage agent decision-making d) To chunk documents into smaller segments Correct Answer: b)
80. "Document processing and chunking strategies" are essential in RAG for: a) Encrypting sensitive data b) Breaking down large documents into manageable segments for retrieval c) Converting images to text d) Analyzing agent performance metrics Correct Answer: b)
81. "Fundamentals of AI agents and autonomous systems" introduces the concept of: a) Static, non-interactive programs b) Intelligent entities that perceive their environment and take actions to achieve goals c) Human-controlled robots only d) Simple data storage systems Correct Answer: b)
82. "Agent workflows and decision-making processes" define: a) The hardware specifications for an agent b) How an AI agent plans, executes, and adapts its actions to accomplish tasks c) The aesthetic design of an AI agent's interface d) The minimum temperature for operation Correct Answer: b)
83. "Multi-modal AI applications development" refers to applications that: a) Only process text data b) Can process and generate content across multiple modalities (e.g., text, images, audio) c) Are deployed on multiple servers d) Use multiple programming languages Correct Answer: b)
84. "Building generative AI-powered applications with Python" highlights the use of Python for: a) Only low-level hardware control b) Implementing and integrating generative AI models into functional applications c) Designing circuit boards d) Writing operating systems Correct Answer: b)
85. "End-to-end project development and deployment" in Unit 6 implies: a) Only theoretical study of project design b) Covering the entire lifecycle from conception, development, to final deployment of AI applications c) Focusing solely on model training d) Ignoring user feedback after deployment Correct Answer: b)
86. What is the primary benefit of incorporating "Retrieval-Augmented Generation (RAG)" into generative AI? a) It makes the model smaller and faster. b) It allows the model to generate text without any external knowledge. c) It grounds the generation in factual, external information, reducing hallucinations and improving relevance. d) It completely replaces the need for fine-tuning. Correct Answer: c)
87. "Similarity search" facilitated by embedding models and vector databases enables: a) Randomly selecting documents b) Finding items (documents, text snippets) that are semantically similar to a query c) Storing data in a traditional relational database d) Only searching for exact keyword matches Correct Answer: b)
88. "LangChain framework" simplifies the development of AI applications by providing: a) Only a user interface for AI models b) Abstractions and tools to chain together LLMs, external data, and agents c) A new programming language for AI d) A proprietary operating system Correct Answer: b)
89. A "vector database" is particularly suitable for RAG applications due to its ability to: a) Store data in tabular format b) Efficiently store and query high-dimensional vector embeddings c) Perform complex joins across multiple tables d) Only store numerical values without context Correct Answer: b)
90. The concept of "semantic search" in RAG focuses on: a) Searching for exact keyword matches b) Understanding the meaning and context of a query to find relevant results c) Only searching within structured databases d) Ignoring the relationships between words Correct Answer: b)
General Course Outcomes & Cross-Unit Topics
91. According to CO1, students will be able to remember fundamental deep learning concepts and identify key components of neural network architectures using: a) PyTorch and Scikit-learn b) Keras and TensorFlow frameworks c) MATLAB and Octave d) C++ and Java Correct Answer: b)
92. CO2 states that students will understand generative AI principles and explain the architecture and data preparation techniques for: a) Traditional expert systems b) Relational databases c) Large Language Models (LLMs) d) Image processing filters Correct Answer: c)
93. CO3 emphasizes applying foundational NLP models and implementing transformer-based language modeling solutions for: a) Hypothetical scenarios only b) Real-world applications c) Benchmarking traditional algorithms d) Creating static web pages Correct Answer: b)
94. What does CO4 focus on regarding fine-tuning techniques? a) Discarding fine-tuning for all applications b) Only using pre-trained models without modification c) Analyzing and evaluating the performance of customized generative AI models for specific domains d) Limiting models to generic tasks Correct Answer: c)
95. CO5 outlines the ability to design advanced AI agent systems by integrating RAG architecture with LangChain to: a) Perform basic arithmetic b) Create intelligent applications c) Only classify data d) Manage cloud infrastructure Correct Answer: b)
96. CO6 aims for students to evaluate generative AI applications and design comprehensive solutions demonstrating mastery of: a) Basic programming syntax b) End-to-end AI development c) Hardware repair d) Networking protocols Correct Answer: b)
97. To be eligible for the Mid Term Examination, students must complete Coursera certificates for courses included in which units? a) Units 4, 5, and 6 b) Units 1, 2, and 3 c) Units 1 and 6 only d) All six units Correct Answer: b)
98. The eligibility criteria for the End Term Examination require the completion of Coursera certificates for how many courses? a) 4 courses b) 6 courses c) 8 courses d) 10 courses Correct Answer: c)
99. Which of the following Coursera courses is required for Mid Term Examination eligibility? a) Generative AI Advance Fine-Tuning for LLMs b) Fundamentals of AI Agents Using RAG and LangChain c) Introduction to Deep Learning & Neural Networks with Keras d) Generative AI Language Modeling with Transformers Correct Answer: c)
100. The full course title mentioned for CSEB402 is: a) Deep Learning Architectures b) Generative AI Fundamentals c) AGENTIC AI FUNDAMENTALS AND IMPLEMENTATIONS d) Keras and TensorFlow Advanced Techniques Correct Answer: c)